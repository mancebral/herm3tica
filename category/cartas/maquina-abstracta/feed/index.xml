<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Máquina Abstracta &#8211; herm3TICa</title>
	<atom:link href="./index.html" rel="self" type="application/rss+xml" />
	<link>./../../../../index.html</link>
	<description>Cámaras, sensores y telepresencia</description>
	<lastBuildDate>Sun, 08 Feb 2015 21:49:04 +0000</lastBuildDate>
	<language>es</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.2</generator>
	<item>
		<title>Dibujando la alfombra de Sierpinski (Shaders y FBO)</title>
		<link>./../../../../dibujando-la-alfombra-de-sierpinski-shaders-y-fbo/index.html</link>
					<comments>./../../../../dibujando-la-alfombra-de-sierpinski-shaders-y-fbo/index.html#respond</comments>
		
		<dc:creator><![CDATA[Horacio]]></dc:creator>
		<pubDate>Sun, 08 Feb 2015 21:46:51 +0000</pubDate>
				<category><![CDATA[Alfombra de Sierpinski]]></category>
		<category><![CDATA[Investigación]]></category>
		<category><![CDATA[Máquina Abstracta]]></category>
		<category><![CDATA[OpenFrameworks]]></category>
		<category><![CDATA[Tech]]></category>
		<category><![CDATA[3]]></category>
		<category><![CDATA[alpha]]></category>
		<category><![CDATA[fbo]]></category>
		<category><![CDATA[fundamentos]]></category>
		<category><![CDATA[interpolación]]></category>
		<category><![CDATA[módulo]]></category>
		<category><![CDATA[pixeles]]></category>
		<category><![CDATA[posición]]></category>
		<category><![CDATA[redimensionado]]></category>
		<category><![CDATA[shaders]]></category>
		<category><![CDATA[sierpinski]]></category>
		<guid isPermaLink="false">./../../../../index.html?p=1133</guid>

					<description><![CDATA[El método que hemos escogido para dibujar la alfombra de Sierpinski en el artículo anterior es muy poco eficiente, la aplicación que lo utiliza, SierpinskiGreyScale, funciona a nueve fotogramas por segundo en mi ordenador. El programa necesita recorrer la matriz de 729 x 729, de la forma en que explicamos, dos veces; una primera vez [...]]]></description>
										<content:encoded><![CDATA[<p style="text-align: justify;"><span style="color: #4c4c4c;">El método que hemos escogido para dibujar la alfombra de Sierpinski en el <a href="./../../../../dibujando-la-alfombra-de-sierpinski-con-pixeles/index.html">artículo anterior</a> es muy poco eficiente, la aplicación que lo utiliza, <a title="SierpinskiGreyScale - Github Alg-a" href="https://github.com/alg-a/herm3TICa/tree/master/exploracion%20pruebas%20y%20juegos/SierpinskiGreyScale" target="_blank">SierpinskiGreyScale</a>, funciona a nueve fotogramas por segundo en mi ordenador. El programa necesita recorrer la matriz de 729 x 729, de la forma en que explicamos, dos veces; una primera vez para sumar los valores de todos los pixeles que están en los cuadrados centrales y una segunda vez para calcular la media de todos los valores sumados dividiendo el resultado por el número de pixeles de cada cuadrado, almacenar la media como escala de grises en las áreas sensibles y crear una textura que muestre el resultado.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/02/sierpinski-shaders_00.png"><img decoding="async" class="alignnone wp-image-1134 size-full" src="./../../../../wp-content/uploads/2015/02/sierpinski-shaders_00.png" alt="sierpinski-shaders_00" width="950" height="292" srcset="./../../../../wp-content/uploads/2015/02/sierpinski-shaders_00.png 950w, ./../../../../wp-content/uploads/2015/02/sierpinski-shaders_00-300x92.png 300w" sizes="(max-width: 950px) 100vw, 950px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">¿Podemos utilizar shaders o aprovechar la forma de trabajar con Frame Buffer Objects que sugerimos en el <a title="Redimensionando una imagen" href="./../../../../redimensionando-una-imagen/index.html">segundo artículo</a>, con el fin de resolver de forma mas eficiente el problema?</span></p>
<p><a href="./../../../../wp-content/uploads/2015/02/sierpinski-shaders_03.png"><img decoding="async" class="alignnone wp-image-1137 size-full" src="./../../../../wp-content/uploads/2015/02/sierpinski-shaders_03.png" alt="sierpinski-shaders_03" width="668" height="329" srcset="./../../../../wp-content/uploads/2015/02/sierpinski-shaders_03.png 668w, ./../../../../wp-content/uploads/2015/02/sierpinski-shaders_03-300x147.png 300w" sizes="(max-width: 668px) 100vw, 668px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Reconsideremos la naturaleza de lo que la alfombra de Sierpinski propone en cada nivel. Comenzamos partiendo de una imagen de 729 x729 que descompusimos en un cuadrado central y ocho zonas de 243 x 243 pixeles. Sin embargo, desde el punto de vista de la alfombra, lo único que necesitábamos era transformar la imagen original en una matriz de 3 x 3 pixeles y seleccionar el pixel central. Podemos realizar este trabajo de forma muy eficiente y con mucha facilidad redimensionando la imagen mediante un Frame Buffer Object.</span></p>
<pre style="font-size: .8em;">// declaración
OfFbo		fbo_1;
ofPixels    pixels_1;
ofTexture	texture_1;

...

// asignacion de memoria
fbo_1.allocate(5, 3, GL_RGB, 0);
texture_1.allocate(5, 3, GL_RGB);
texture_1.setTextureMinMagFilter(GL_NEAREST, GL_NEAREST);

...

fbo_1.begin();
ofClear(0, 0, 0, 255);
videoTexture.draw(0, 0, 3, 3);
fbo_1.end();
fbo_1.readToPixels(pixels_1);
texture_1.loadData(pixels_1.getPixels(), 5, 3, GL_RGB);</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Al hacerlo nos hemos encontrado con un extraño problema, trabajando con texturas y Frame Buffer Objects cuyo ancho era un múltiplo exacto de 3, la tarjeta gráfica del ordenador generaba extraños errores y fallos. Sin haber ocupado mucho tiempo en averiguar porqué sucede esto, para resolver el problema, hemos decidido utilizar anchos 2 pixeles más grandes de lo que necesitamos, por esta razón en el fragmento de código anterior la textura y el Frame Buffer Object tienen un tamaño de 5 x 3 pixeles.</span></p>
<pre style="font-size: .8em;">texture_1.setTextureMinMagFilter(GL_NEAREST, GL_NEAREST);</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">La clave de esta nueva estrategia que proponemos está en la sexta línea del código. La función setTextureMinMagFilter nos permite establecer la forma en que se renderizará la textura en la que almacenamos la matriz de 3 x 3 pixeles del primer nivel de la alfombra, de modo que mantenga su geometría aunque la mostremos en la pantalla a un tamaño de 729 x 729, debido al tipo de cálculo que se realizará para generar por interpolación los 531.441 pixeles que habrá en la pantalla para representar una textura que solamente tiene 9 pixeles, GL_NEAREST.</span></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">A continuación simplemente debemos realizar la misma operación para almacenar cada nivel de la alfombra en una textura del tamaño adecuado, 9 x 9, 27 x 27, 81 x 81 y 243 x 243.</span></p>
<pre style="font-size: .8em;">// declaración
OfFbo		fbo_2;
ofPixels    pixels_2;
ofTexture	texture_2;

...

// asignacion de memoria
fbo_2.allocate(11, 9, GL_RGB, 0);
texture_2.allocate(11, 9, GL_RGB);
texture_2.setTextureMinMagFilter(GL_NEAREST, GL_NEAREST);

...

fbo_2.begin();
ofClear(0, 0, 0, 255);
videoTexture.draw(0, 0, 9, 9);
fbo_2.end();
fbo_2.readToPixels(pixels_2);
texture_2.loadData(pixels_2.getPixels(), 11, 9, GL_RGB);

...</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">De hecho podemos simplificar muchísimo el código almacenando Frame Buffer Objects, texturas, pixeles y tamaños en arrays, para hacer todas las operaciones en el contexto de un bucle for.</span></p>
<pre style="font-size: .8em;">// declaración
OfFbo		fbo[6];
ofPixels    pix[6];
ofTexture	texture[6];
int         w[6];
int         h[6];

...

// asignacion de memoria
for (int i=0; i&lt;6; i++) {
	fbo[i].allocate(w[i], h[i], GL_RGB, 0);
	texture[i].allocate(w[i], h[i], GL_RGB);
	texture[i].setTextureMinMagFilter(GL_NEAREST, GL_NEAREST);
}

...

for (int i=0; i&lt;6; i++) {
  	fbo[i].begin();
	ofClear(0, 0, 0, 255);
	videoTexture.draw(0,0, w[i]-2, h[i]);
	fbo[i].end();
	fbo[i].readToPixels(pix[i]);
	texture[i].loadData(Pix[i].getPixels(), w[i], h[i], GL_RGB);
}</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Una vez hayamos almacenado cada uno de los niveles de la alfombra en una textura diferente solamente nos quedará el delicado trabajo de mostrarlas unas encima de otras de modo que únicamente sean visibles los cuadrados centrales.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/02/01-mago-composit.png"><img decoding="async" class="alignnone wp-image-1148 size-large" src="./../../../../wp-content/uploads/2015/02/01-mago-composit-1024x686.png" alt="01-mago-composit" width="1024" height="686" srcset="./../../../../wp-content/uploads/2015/02/01-mago-composit-1024x686.png 1024w, ./../../../../wp-content/uploads/2015/02/01-mago-composit-300x201.png 300w, ./../../../../wp-content/uploads/2015/02/01-mago-composit.png 1132w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Recurramos a la misma lógica que seguimos en el artículo anterior. En el primer nivel el cuadrado central corresponde a un pixel cuyas coordenadas X e Y en la matriz de 3 x 3 son 1 y 1. En el segundo nivel tenemos una matriz de 9 x 9, con ocho zonas de 3 x 3 pixeles dentro de las cuales debemos seleccionar un cuadrado central que, a su vez, corresponde a un pixel cuyas coordenadas X e Y son, otra vez, 1 y 1. Al margen de la posición en la que esté cada pixel central, el resto de la división entera de sus coordenadas de entre 3 será siempre 1, ya que se tratará del segundo pixel de un grupo de tres pixeles, el número 1 contando a partir del 0.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/02/sierpinski-shaders_04.png"><img decoding="async" class="alignnone wp-image-1149 size-full" src="./../../../../wp-content/uploads/2015/02/sierpinski-shaders_04.png" alt="sierpinski-shaders_04" width="720" height="213" srcset="./../../../../wp-content/uploads/2015/02/sierpinski-shaders_04.png 720w, ./../../../../wp-content/uploads/2015/02/sierpinski-shaders_04-300x88.png 300w" sizes="(max-width: 720px) 100vw, 720px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">En todos y cada uno de los niveles sucede exactamente lo mismo, el cuadrado central se corresponde con el segundo pixel de un grupo de tres, por lo tanto, podemos utilizar un shader para cambiar la transparencia de todos los pixeles de las texturas que hemos creado en función de sus coordenadas y hacer visibles solamente los cuadrados centrales. Bastará con asignar 0 al valor del canal alpha de cada pixel, cuando el resto de la división entera de sus coordenadas entre tres no sea 1 en ambos ejes.</span></p>
<pre style="font-size: .8em;">uniform sampler2DRect tex0;
in vec2 texCoordVarying;

out vec4 outputColor;

void main() {
	 
	vec4 texel0 = texture(tex0, texCoordVarying);
	float alpha = 1.0;
	((floor(mod(texCoordVarying.x, 3)) == 1) &amp;&amp; (floor(mod(texCoordVarying.y, 3)) == 1)) ? alpha = 1.0 : alpha = 0.0;
	if ((texel0.r == 0) &amp;&amp; (texel0.g == 0) &amp;&amp; (texel0.b == 0)) alpha = 0.0;
	outputColor = vec4(texel0.r, texel0.g, texel0.b, alpha);
	
}</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Hemos utilizado esta estrategia para hacer una segunda aplicación y el resultado es asombroso, el nuevo programa permite dibujar un Sierpinski a partir del feedback de la webcam el doble de grande, 1458 x 729, y sin embargo funciona a 50 fotogramas por segundo.</span></p>
<p><a title="Sierpinski Shaders - Github Alg-a" href="https://github.com/alg-a/herm3TICa/tree/master/exploracion%20pruebas%20y%20juegos/SierpinskiShaders">https://github.com/alg-a/herm3TICa/tree/master/exploracion%20pruebas%20y%20juegos/SierpinskiShaders</a></p>
]]></content:encoded>
					
					<wfw:commentRss>./../../../../dibujando-la-alfombra-de-sierpinski-shaders-y-fbo/feed/index.html</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Dibujando la alfombra de Sierpinski con pixeles</title>
		<link>./../../../../dibujando-la-alfombra-de-sierpinski-con-pixeles/index.html</link>
					<comments>./../../../../dibujando-la-alfombra-de-sierpinski-con-pixeles/index.html#respond</comments>
		
		<dc:creator><![CDATA[Horacio]]></dc:creator>
		<pubDate>Sat, 07 Feb 2015 22:10:00 +0000</pubDate>
				<category><![CDATA[Alfombra de Sierpinski]]></category>
		<category><![CDATA[code]]></category>
		<category><![CDATA[Investigación]]></category>
		<category><![CDATA[Máquina Abstracta]]></category>
		<category><![CDATA[OpenFrameworks]]></category>
		<category><![CDATA[Tech]]></category>
		<category><![CDATA[3]]></category>
		<category><![CDATA[cálculo coordenadas]]></category>
		<category><![CDATA[fundamentos]]></category>
		<category><![CDATA[iteración]]></category>
		<category><![CDATA[módulo]]></category>
		<category><![CDATA[pixeles]]></category>
		<category><![CDATA[posición]]></category>
		<category><![CDATA[sierpinski]]></category>
		<guid isPermaLink="false">./../../../../index.html?p=1109</guid>

					<description><![CDATA[Hagamos el ejercicio de intentar llevar la lógica del conjunto fractal de la alfombra de Sierpinski al nivel del pixel. Para hacerlo necesitaremos trabajar con imágenes cuyas dimensiones sean potencia de 3, de modo que podamos ir dividiendo sucesivamente el ancho y el alto de la imagen en tres partes iguales, hasta llegar a un [...]]]></description>
										<content:encoded><![CDATA[<p><a href="./../../../../wp-content/uploads/2015/02/self_portrait_sierpinski.png"><img decoding="async" class="alignnone wp-image-1110 size-full" src="./../../../../wp-content/uploads/2015/02/self_portrait_sierpinski.png" alt="self_portrait_sierpinski" width="1458" height="729" srcset="./../../../../wp-content/uploads/2015/02/self_portrait_sierpinski.png 1458w, ./../../../../wp-content/uploads/2015/02/self_portrait_sierpinski-300x150.png 300w, ./../../../../wp-content/uploads/2015/02/self_portrait_sierpinski-1024x511.png 1024w, ./../../../../wp-content/uploads/2015/02/self_portrait_sierpinski-1000x500.png 1000w" sizes="(max-width: 1458px) 100vw, 1458px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Hagamos el ejercicio de intentar llevar la lógica del conjunto fractal de la alfombra de Sierpinski al nivel del pixel. Para hacerlo necesitaremos trabajar con imágenes cuyas dimensiones sean potencia de 3, de modo que podamos ir dividiendo sucesivamente el ancho y el alto de la imagen en tres partes iguales, hasta llegar a un fragmento de 1 x 1 pixel.</span></p>
<pre style="font-size: .8em;">1, 3, 9, 27, 81, 243, 729 ...</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Usemos una imagen de 729 x 729 pixeles para dibujar un Sierpinski de 6 niveles. ¿Cómo podemos saber que pixeles corresponden al cuadrado central de 243 x 243 cuando recorremos la matriz?<br />
</span></p>
<p><a href="./../../../../wp-content/uploads/2015/02/sierpinski_00.png"><img decoding="async" class="alignnone wp-image-1112 size-full" src="./../../../../wp-content/uploads/2015/02/sierpinski_00.png" alt="sierpinski_00" width="904" height="770" srcset="./../../../../wp-content/uploads/2015/02/sierpinski_00.png 904w, ./../../../../wp-content/uploads/2015/02/sierpinski_00-300x255.png 300w" sizes="(max-width: 904px) 100vw, 904px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Lo primero que necesitaremos es conocer las coordenadas X e Y de cada pixel en función de su índice, para lo que utilizaremos el sistema de cálculo que propusimos en el <a title="Contando pixeles" href="./../../../../contando-pixeles/index.html">artículo 01</a>. También es importante recordar que multiplicaremos todas las medidas por 3 ya que, para cada pixel, en realidad hay tres valores almacenados en la matriz, R, G y B.</span></p>
<pre style="font-size: .8em;">for (int i=0; i&lt;totalPixels; i++) {

	int x = i % (width * 3);
	int y = (i - x) / (width * 3);

	// do something with x and y  …

}</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Como el ancho de nuestra imagen es de 729 pixeles, los pixeles del extremo izquierdo empiezan en la coordenada X = 0 y los del extremo derecho acaban en la coordenada X = 728. Por lo tanto, si dividimos la coordenada X de cualquiera de los pixeles entre 243 siempre obtendremos un valor entre 0 y 2,996, que será inferior a 1 cuando se trate de pixeles de la zona anterior al cuadrado central, estará entre 1 y 2 cuando se trate de pixeles de la zona central y será igual o superior a 2 cuando se trate de pixeles de la zona posterior.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/02/sierpinski_03.png"><img decoding="async" class="alignnone wp-image-1113 size-full" src="./../../../../wp-content/uploads/2015/02/sierpinski_03.png" alt="sierpinski_03" width="1036" height="184" srcset="./../../../../wp-content/uploads/2015/02/sierpinski_03.png 1036w, ./../../../../wp-content/uploads/2015/02/sierpinski_03-300x53.png 300w, ./../../../../wp-content/uploads/2015/02/sierpinski_03-1024x181.png 1024w" sizes="(max-width: 1036px) 100vw, 1036px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Si queremos obtener un número entero al dividir y evitar trabajar con decimales, podemos calcular el resto de la división entera y restarlo previamente, utilizando el operador módulo. Así obtendremos un valor igual a 0 para todos los pixeles de la zona anterior al cuadrado, </span><span style="color: #4c4c4c;">igual a 1 para todos los pixeles del cuadrado central e igual a 2 para todos los pixeles de la zona posterior.</span></p>
<pre style="font-size: .8em;">	int resto_x = x % (243 * 3);
	int zona_x  = (x - resto_x) / (243 * 3);</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Realizando el mismo cálculo en el eje Y, podemos establecer que todos aquellos pixeles en los que obtengamos 1 y 1 como resultados, están situados en el cuadrado central de la imagen.<br />
</span></p>
<pre style="font-size: .8em;">for (int i=0; i&lt;totalPixels; i++) {

	int x = i % (width * 3);
	int y = (i - x) / (width * 3);

	int resto_x = x % (243 * 3);
	int resultado_x  = (x - resto_x) / (243 * 3);
	int resto_y = y % (243 * 3);
	int resultado_y  = (y - resto_y) / (243 * 3);

	if ((resultado_x == 1)&amp;&amp;(resultado_y == 1)) {
		// do something with pixels[i]  ...
	}

}</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Una vez sabemos qué pixeles están en el cuadrado central del primer nivel, intentemos averiguar cuales de los pixeles que no están en dicho cuadrado, están en los cuadrados centrales de de las 8 áreas que quedan definidas a su alrededor. Cada una de estas nuevas zonas tiene un tamaño de 243 x 243 pixeles y, a su vez, sus cuadrados centrales miden 81 x 81 pixeles. ¿Como podemos averiguar las coordenadas X e Y de cada pixel dentro de este nuevo marco de referencia?</span></p>
<p><a href="./../../../../wp-content/uploads/2015/02/sierpinski_01.png"><img decoding="async" class="alignnone wp-image-1115 size-full" src="./../../../../wp-content/uploads/2015/02/sierpinski_01.png" alt="sierpinski_01" width="862" height="756" srcset="./../../../../wp-content/uploads/2015/02/sierpinski_01.png 862w, ./../../../../wp-content/uploads/2015/02/sierpinski_01-300x263.png 300w" sizes="(max-width: 862px) 100vw, 862px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Reflexionemos un poco, ¡en realidad ya las conocemos! Los restos de la división entera, que calculamos con el operador módulo, nos indican dichas coordenadas ya que equivalen al número de pixeles que hemos recorrido desde que sobrepasamos la zona anterior a aquella en la que estamos.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/02/sierpinski_04.png"><img decoding="async" class="alignnone wp-image-1116 size-full" src="./../../../../wp-content/uploads/2015/02/sierpinski_04.png" alt="sierpinski_04" width="1036" height="184" srcset="./../../../../wp-content/uploads/2015/02/sierpinski_04.png 1036w, ./../../../../wp-content/uploads/2015/02/sierpinski_04-300x53.png 300w, ./../../../../wp-content/uploads/2015/02/sierpinski_04-1024x181.png 1024w" sizes="(max-width: 1036px) 100vw, 1036px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Saber que pixeles están en los nuevos cuadrados centrales, en realidad, es un problema que ya hemos resuelto con una matriz de diferentes dimensiones. Solamente tenemos que aplicar la misma lógica que en el primer nivel, considerando que ahora tenemos una matriz de 243 x 243 con un cuadrado central de 81 x 81 pixeles.</span></p>
<pre style="font-size: .8em;">	if ((resultado_x == 1)&amp;&amp;(resultado_y == 1)) {
		// do something with pixels[i]  ...
	} else {
		int x1 = resto_x;
		int y1 = resto_y;
		
		int resto_x1 = x1 % (81 * 3);
		int resultado_x1  = (x1 - resto_x1) / (81 * 3);
		int resto_y1 = y1 % (81 * 3);
		int resultado_y1  = (y1 - resto_y1) / (81 * 3);

		if ((resultado_x1 == 1)&amp;&amp;(resultado_y1 == 1)) {
			// do something with pixels[i]  ...
		}
	}</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Aplicando el mismo sistema podemos proseguir sucesivamente con cuadrados cada vez más pequeños, de 27 x 27, de 9 x 9 y, finalmente de 3 x 3, el último nivel al que podemos llegar trabajando con pixeles.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/02/sierpinski_02.png"><img decoding="async" class="alignnone wp-image-1118 size-full" src="./../../../../wp-content/uploads/2015/02/sierpinski_02.png" alt="sierpinski_02" width="744" height="732" srcset="./../../../../wp-content/uploads/2015/02/sierpinski_02.png 744w, ./../../../../wp-content/uploads/2015/02/sierpinski_02-300x295.png 300w" sizes="(max-width: 744px) 100vw, 744px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">En la siguiente aplicación encontrareis un ejemplo de como hemos combinado el concepto de áreas de activación, descrito en el <a title="Areas de activacion" href="./../../../../el-mago-areas-de-activacion/index.html">articulo 00</a>, con la alfombra de Sierpinski, para definir una retícula de zonas sensibles, activables y desactivables, con la que interactuar a través de una web cam.</span></p>
<p><a title="SierpinskiGreyScale - Github Alg-a" href="https://github.com/alg-a/herm3TICa/tree/master/exploracion%20pruebas%20y%20juegos/SierpinskiGreyScale" target="_blank">https://github.com/alg-a/herm3TICa/tree/master/exploracion%20pruebas%20y%20juegos/SierpinskiGreyScale</a></p>
]]></content:encoded>
					
					<wfw:commentRss>./../../../../dibujando-la-alfombra-de-sierpinski-con-pixeles/feed/index.html</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Redimensionando una imagen</title>
		<link>./../../../../redimensionando-una-imagen/index.html</link>
					<comments>./../../../../redimensionando-una-imagen/index.html#respond</comments>
		
		<dc:creator><![CDATA[Horacio]]></dc:creator>
		<pubDate>Mon, 26 Jan 2015 09:35:17 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[Investigación]]></category>
		<category><![CDATA[Máquina Abstracta]]></category>
		<category><![CDATA[OpenFrameworks]]></category>
		<category><![CDATA[Previos]]></category>
		<category><![CDATA[Tech]]></category>
		<category><![CDATA[fbo]]></category>
		<category><![CDATA[fundamentos]]></category>
		<category><![CDATA[interpolación]]></category>
		<category><![CDATA[pixeles]]></category>
		<category><![CDATA[redimensionado]]></category>
		<guid isPermaLink="false">./../../../../index.html?p=947</guid>

					<description><![CDATA[Si queremos trabajar exclusivamente en un fragmento de una imagen, o queremos redimensionarla, ampliar o reducir su tamaño, la forma más sencilla de trabajar consiste en leer los pixeles de la matriz original y copiar aquellos que vamos a utilizar en una nueva matriz que tenga el tamaño deseado. En este tipo de situación trabajamos [...]]]></description>
										<content:encoded><![CDATA[<p><a href="./../../../../wp-content/uploads/2015/01/02-sacerdotisa-detalle.png"><img decoding="async" class="alignnone wp-image-948 size-full" src="./../../../../wp-content/uploads/2015/01/02-sacerdotisa-detalle.png" alt="02-sacerdotisa-detalle" width="654" height="336" srcset="./../../../../wp-content/uploads/2015/01/02-sacerdotisa-detalle.png 654w, ./../../../../wp-content/uploads/2015/01/02-sacerdotisa-detalle-300x154.png 300w" sizes="(max-width: 654px) 100vw, 654px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Si queremos trabajar exclusivamente en un fragmento de una imagen, o queremos redimensionarla, ampliar o reducir su tamaño, la forma más sencilla de trabajar consiste en leer los pixeles de la matriz original y copiar aquellos que vamos a utilizar en una nueva matriz que tenga el tamaño deseado. En este tipo de situación trabajamos con dos imágenes o matrices de pixeles, la fuente y el resultado, que generalmente tienen tamaños diferentes, una es mas grande que la otra, por lo que o bien es necesario duplicar pixeles, cuando la imagen resultado es mas grande, o bien es necesario saltarse algunos de los pixeles, cuando la imagen resultado es mas pequeña.</span></p>
<p style="text-align: justify;"><a href="./../../../../wp-content/uploads/2015/01/matrices.png"><img decoding="async" class="alignnone wp-image-953 size-full" src="./../../../../wp-content/uploads/2015/01/matrices.png" alt="matrices" width="460" height="188" srcset="./../../../../wp-content/uploads/2015/01/matrices.png 460w, ./../../../../wp-content/uploads/2015/01/matrices-300x122.png 300w" sizes="(max-width: 460px) 100vw, 460px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">La solución ideal para este tipo de casos consiste en realizar algunos cálculos llamados interpolaciones que permiten introducir pixeles con valores intermedios en la nueva imagen o obtener una valor medio de los pixeles que no utilizamos. Sin embargo, en muchas ocasiones duplicar o saltarse pixeles ofrece un resultado suficientemente correcto y basta con leer los datos de la imagen fuente mientras recorremos la matriz de la imagen resultado para realizar el trabajo.</span></p>
<p style="text-align: justify;"><a href="./../../../../wp-content/uploads/2015/01/interpolaciones.png"><img decoding="async" class="alignnone wp-image-949 size-full" src="./../../../../wp-content/uploads/2015/01/interpolaciones.png" alt="interpolaciones" width="470" height="148" srcset="./../../../../wp-content/uploads/2015/01/interpolaciones.png 470w, ./../../../../wp-content/uploads/2015/01/interpolaciones-300x94.png 300w" sizes="(max-width: 470px) 100vw, 470px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Si empleamos el sistema que utilizamos en el ejercicio anterior para recorrer la matriz de la imagen resultado pixel a pixel y obtener su posición x e y, resulta bastante sencillo calcular la posición que corresponde a ese pixel en la imagen fuente haciendo el cálculo inverso. Basta con sumar el margen lateral izquierdo a la coordenada x y el margen superior a la coordenada, si estamos realizando un recorte, y hacer el siguiente cálculo: [numero de lineas recorridas * ancho de la imagen fuente + posición por la que vamos en la linea actual].</span></p>
<pre style="font-size: .8em;">for (int i=0; i&lt;pixelesResultado; i++) {
        int x = i % (anchoResultado * 3);
        int y = (i - x) / ( anchoResultado * 3);
        x += margenIzquierdo*3;
        y += margenSuperior;
        int nuevaPosicion = (y * anchoFuente * 3 + x);
}
</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">¿Es posible evitar realizar este trabajo? Sí, en lugar de hacerlo nosotros, podemos pedirle a la tarjeta gráfica que lo haga. Imaginemonos que pudiésemos dibujar la imagen fuente ampliándola o reduciéndola de tamaño, haciendo incluso que parte de la imagen quede fuera de la pantalla de modo que solamente sea visible el fragmento que queramos utilizar. Si pudiéramos hacerlo y ademas consiguiésemos capturar la pantalla y almacenarla en una nueva matriz, habríamos realizado el trabajo sin hacer casi ningún esfuerzo. Eso es precisamente lo que permite hacer un FBO (Frame Buffer Object), dibujar en un objeto como si lo hiciésemos en la pantalla y reutilizar después el conjunto de pixeles dibujados.</span></p>
<pre style="font-size: .8em;">// declaración
ofFbo fbo; // Frame buffer object
ofPixels pixeles; // objecto para almacenar y copiar pixeles
ofTexture texture; // Textura o imagen original
ofTexture newTexture; // Textura resultante

...

// asignacion de memoria  
texture.allocate(antiguoAncho, antiguoAlto, GL_RGB);    
newTexture.allocate(nuevoAncho, nuevoAlto, GL_RGB);        
fbo.allocate(nuevoAncho, nuevoAlto, GL_RGB, 0);

...

// redimensionado
fbo.begin();
texture.draw(0, 0, nuevoAncho, nuevoAlto); // tambien se puede dibujar la imagen mas grande para hacer un recorte
fbo.end();
fbo.readToPixels(pixeles);
newTexture.loadData(pixeles.getPixels(), nuevoAncho, nuevoAlto, GL_RGB);
</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">La gran ventaja de esta nueva estrategia es que la tarjeta gráfica esta diseñada para realizar este tipo de trabajo, por lo que el proceso resultará mucho mas eficiente. Pero además, podremos controlar la forma en que se calculan pixeles que antes simplemente duplicábamos o nos saltábamos, sin necesidad de hacer ningún trabajo, bastará indicarle previamente a la tarjeta gráfica el tipo de interpolaciones que queremos que haga con la textura que dibujemos.</span></p>
<pre style="font-size: .8em;">texture.setTextureMinMagFilter(GL_NEAREST, GL_NEAREST);
</pre>
]]></content:encoded>
					
					<wfw:commentRss>./../../../../redimensionando-una-imagen/feed/index.html</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Contando pixeles.</title>
		<link>./../../../../contando-pixeles/index.html</link>
		
		<dc:creator><![CDATA[Horacio]]></dc:creator>
		<pubDate>Sun, 11 Jan 2015 17:42:52 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[Investigación]]></category>
		<category><![CDATA[Máquina Abstracta]]></category>
		<category><![CDATA[OpenFrameworks]]></category>
		<category><![CDATA[Tech]]></category>
		<category><![CDATA[bucles]]></category>
		<category><![CDATA[fundamentos]]></category>
		<category><![CDATA[iteración]]></category>
		<category><![CDATA[pixeles]]></category>
		<guid isPermaLink="false">./../../../../index.html?p=819</guid>

					<description><![CDATA[Una de las tareas que realizaremos a menudo cuando trabajemos con video en openframeworks será recorrer la matriz de pixeles en la que se almacena cada fotograma procedente de la cámara o de la película que estemos reproduciendo. En openframeworks, dicha matriz no es bidimensional, sino que los valores RGB se almacenan, unos al lado [...]]]></description>
										<content:encoded><![CDATA[<p style="text-align: justify;"><span style="color: #4c4c4c;">Una de las tareas que realizaremos a menudo cuando trabajemos con video en openframeworks será recorrer la matriz de pixeles en la que se almacena cada fotograma procedente de la cámara o de la película que estemos reproduciendo. En openframeworks, dicha matriz no es bidimensional, sino que los valores RGB se almacenan, unos al lado de los otros, en una larga lista.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/01/carta-mago-00.png"><img decoding="async" class="alignnone wp-image-822 size-large" src="./../../../../wp-content/uploads/2015/01/carta-mago-00-1024x62.png" alt="carta-mago-00" width="1024" height="62" srcset="./../../../../wp-content/uploads/2015/01/carta-mago-00-1024x62.png 1024w, ./../../../../wp-content/uploads/2015/01/carta-mago-00-300x18.png 300w, ./../../../../wp-content/uploads/2015/01/carta-mago-00.png 1436w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Es importante recordar que, por cada pixel, en la lista se almacenan tres valores; uno para la luminosidad del color rojo, otro para la luminosidad del color verde, y otro para la luminosidad del color azul. Por lo tanto, cualquier matriz de pixeles que utilicemos procedente de una imagen RGB estará compuesta por un numero valores igual al total de pixeles multiplicado por 3.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/01/carta-mago-01.png"><img decoding="async" class="alignnone wp-image-823 size-large" src="./../../../../wp-content/uploads/2015/01/carta-mago-01-1024x62.png" alt="carta-mago-01" width="1024" height="62" srcset="./../../../../wp-content/uploads/2015/01/carta-mago-01-1024x62.png 1024w, ./../../../../wp-content/uploads/2015/01/carta-mago-01-300x18.png 300w, ./../../../../wp-content/uploads/2015/01/carta-mago-01.png 1436w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Para recorrer la matriz y realizar operaciones en cada uno de los pixeles basta con hacer una, muy sencilla, iteración con un índice que nos permita ir del primer elemento de la lista hasta el último.</span></p>
<pre style="font-size: .8em;">unsigned char * pixels = vidGrabber.getPixels();
int totalPixels = camWidth * camHeight * 3;
for (int i = 0; i &lt; totalPixels; i++) {
	// do something with pixels[i]  ...
}
</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Sin embargo, en muchas ocasiones, será necesario conocer la posición X e Y da cada pixel en la imagen, como por ejemplo, cuando queramos cambiar su tamaño, trabajar en un fragmento de la misma o hacer operaciones basadas en líneas horizontales o verticales. En ese caso la solución mas directa consiste en trabajar como si la matriz de vídeo tuviese dos dimensiones y hacer dos iteraciones, con dos índices, uno que recorra la matriz a lo alto y otro que la recorra a lo ancho. De este modo, avanzaremos a través de la imagen, de línea horizontal en línea horizontal, empezando por la parte superior izquierda y acabando en la parte inferior derecha y, en cada punto de la iteración, los índices tomarán el valor de la posición X e Y de uno de los pixeles; con ellos, podremos calcular fácilmente la posición de dicho pixel en la lista.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/01/lectura_pixeles_00.png"><img decoding="async" class="alignnone wp-image-830 size-large" src="./../../../../wp-content/uploads/2015/01/lectura_pixeles_00-626x1024.png" alt="lectura_pixeles_00" width="626" height="1024" srcset="./../../../../wp-content/uploads/2015/01/lectura_pixeles_00-626x1024.png 626w, ./../../../../wp-content/uploads/2015/01/lectura_pixeles_00-183x300.png 183w, ./../../../../wp-content/uploads/2015/01/lectura_pixeles_00.png 734w" sizes="(max-width: 626px) 100vw, 626px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Al igual que en el ejemplo anterior es importante recordar que por cada pixel se almacenan tres valores en la lista, por lo que el ancho de de una matriz de dos dimensiones en la que estuviese almacenada la imagen sería tres veces el ancho en pixeles de la imagen.</span></p>
<pre style="font-size: .8em;">unsigned char * pixels = vidGrabber.getPixels();
for (int y=0; y&lt;camHeight; y++) {
	for (int x = 0; x &lt; (camWidth * 3); x++){
		int position = y * (camWidth * 3) + x;
		// do something with pixels[pos]  ...
	}
}
</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Siguiendo la misma estrategia, en uno de los <a href="http://forum.openframeworks.cc/t/nested-iteration-over-all-pixels-of-ofxcvgrayscaleimage/14039">foros de openframeworks</a>, Arturo Castro propone simplificar el proceso utilizando un tercer índice para calcular de forma directa la posición en la lista.</span></p>
<pre style="font-size: .8em;">unsigned char * pixels = vidGrabber.getPixels();
int i = 0;
for (int y=0; y&lt;camHeight; y++) {
	for (int x = 0; x &lt; (camWidth * 3); x++, i++){
		// do something with pixels[i]  ...
	}
}
</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">La opción propuesta por Arturo Castro es extraordinariamente elegante, pero en los ejemplos de herm3TICa, a menudo, utilizaremos una estrategia diferente sugerida por Emanuele Mazza, que permite reducir el número de iteraciones haciendo algunas matemáticas. Consiste en utilizar un operador llamado módulo <em>%</em>, que devuelve el resto de una división con números enteros, para calcular la posición X e Y de cada pixel partiendo de su índice.</span></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Si recorremos la matriz a través de un único índice, como en el primer ejemplo, y en cada iteración calculamos el resto de la división de dicho índice entre el ancho de la matriz utilizando el operador módulo, el resto equivaldrá la posición X de cada pixel. Del mismo modo si calculamos la división con números enteros del índice entre el ancho de la matriz, restando previamente ese resto al índice, el resultado equivaldrá la posición Y de cada pixel. </span></p>
<pre style="font-size: .8em;">unsigned char * pixels = vidGrabber.getPixels();
int totalPixels = camWidth * camHeight * 3;
for (int i=0; i&lt;totalPixels; i++) {
	int x = i % (camWidth * 3);
	int y = (i - x) / (camWidth * 3);
	// do something with pixels[i]  ...
}
</pre>
<p style="text-align: justify;"><span style="color: #4c4c4c;">La lógica de la operación es mucho mas sencilla de lo que aparenta; por cada línea que recorremos, avanzamos un total de valores igual al ancho de la supuesta matriz bidimensional. </span></p>
<p><a href="./../../../../wp-content/uploads/2015/01/lectura_pixeles_01.png"><img decoding="async" class="alignnone wp-image-825 size-large" src="./../../../../wp-content/uploads/2015/01/lectura_pixeles_01-1024x75.png" alt="lectura_pixeles_01" width="1024" height="75" srcset="./../../../../wp-content/uploads/2015/01/lectura_pixeles_01-1024x75.png 1024w, ./../../../../wp-content/uploads/2015/01/lectura_pixeles_01-300x22.png 300w, ./../../../../wp-content/uploads/2015/01/lectura_pixeles_01.png 1458w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;"><span style="color: #4c4c4c;">Si, por ejemplo, estamos al principio de la tercera línea, habremos avanzado dos veces el ancho de la matriz y el resultado de la división del índice entre el ancho matriz deberá ser dos. Sin embargo nos encontramos en la tercera línea, ¿por que? En realidad la tercera línea es la número dos ya que, al igual que en el Tarot, comenzamos a contar a partir del 0, es decir, contamos las líneas que hemos recorrido, no la línea en la que estamos. La primera línea, la línea 0, es la línea en la que todavía no hemos recorrido ninguna otra línea</span>.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/01/lectura_pixeles_02.png"><img decoding="async" class="alignnone wp-image-826 size-large" src="./../../../../wp-content/uploads/2015/01/lectura_pixeles_02-1024x75.png" alt="lectura_pixeles_02" width="1024" height="75" srcset="./../../../../wp-content/uploads/2015/01/lectura_pixeles_02-1024x75.png 1024w, ./../../../../wp-content/uploads/2015/01/lectura_pixeles_02-300x22.png 300w, ./../../../../wp-content/uploads/2015/01/lectura_pixeles_02.png 1458w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">En el ejemplo de la imagen si dividimos el índice, 14, entre 7 el resultado es 2 y el resto cero, por lo que el índice 14 se encuentra la posición 0 de la segunda línea.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/01/lectura_pixeles_04.png"><img decoding="async" class="alignnone wp-image-828 size-large" src="./../../../../wp-content/uploads/2015/01/lectura_pixeles_04-626x1024.png" alt="lectura_pixeles_04" width="626" height="1024" srcset="./../../../../wp-content/uploads/2015/01/lectura_pixeles_04-626x1024.png 626w, ./../../../../wp-content/uploads/2015/01/lectura_pixeles_04-183x300.png 183w, ./../../../../wp-content/uploads/2015/01/lectura_pixeles_04.png 734w" sizes="(max-width: 626px) 100vw, 626px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Por el contrario, si la división del índice entre el ancho de la matriz no es exacta, quiere decir que todavía no hemos alcanzado el final de una de las líneas. En ese caso el valor entero de la división corresponde al número de líneas que ya hemos avanzado y el resto el lugar por el que vamos en la línea que no hemos acabado.<br />
</span></p>
<p><a href="./../../../../wp-content/uploads/2015/01/lectura_pixeles_03.png"><img decoding="async" class="alignnone wp-image-827 size-large" src="./../../../../wp-content/uploads/2015/01/lectura_pixeles_03-1024x75.png" alt="lectura_pixeles_03" width="1024" height="75" srcset="./../../../../wp-content/uploads/2015/01/lectura_pixeles_03-1024x75.png 1024w, ./../../../../wp-content/uploads/2015/01/lectura_pixeles_03-300x22.png 300w, ./../../../../wp-content/uploads/2015/01/lectura_pixeles_03.png 1458w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;"><span style="color: #4c4c4c;">En el ejemplo de la imagen si dividimos el índice, 8, entre 7 </span>el resultado es 1 y el resto 1, por lo que el índice 8 se encuentra en la segunda posición de la segunda línea.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/01/lectura_pixeles_05.png"><img decoding="async" class="alignnone wp-image-829 size-large" src="./../../../../wp-content/uploads/2015/01/lectura_pixeles_05-626x1024.png" alt="lectura_pixeles_05" width="626" height="1024" srcset="./../../../../wp-content/uploads/2015/01/lectura_pixeles_05-626x1024.png 626w, ./../../../../wp-content/uploads/2015/01/lectura_pixeles_05-183x300.png 183w, ./../../../../wp-content/uploads/2015/01/lectura_pixeles_05.png 734w" sizes="(max-width: 626px) 100vw, 626px" /></a></p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>El mago (áreas de activación)</title>
		<link>./../../../../el-mago-areas-de-activacion/index.html</link>
					<comments>./../../../../el-mago-areas-de-activacion/index.html#respond</comments>
		
		<dc:creator><![CDATA[Horacio]]></dc:creator>
		<pubDate>Fri, 09 Jan 2015 21:58:10 +0000</pubDate>
				<category><![CDATA[interactivos]]></category>
		<category><![CDATA[Investigación]]></category>
		<category><![CDATA[Máquina Abstracta]]></category>
		<category><![CDATA[OpenFrameworks]]></category>
		<category><![CDATA[Previos]]></category>
		<category><![CDATA[Tech]]></category>
		<category><![CDATA[botón]]></category>
		<category><![CDATA[captura]]></category>
		<category><![CDATA[code]]></category>
		<category><![CDATA[fundamentos]]></category>
		<category><![CDATA[interacción]]></category>
		<category><![CDATA[trigger area]]></category>
		<category><![CDATA[video]]></category>
		<guid isPermaLink="false">./../../../../index.html?p=761</guid>

					<description><![CDATA[(…) el Mago arroja los 4 elementos; con los que puede hacer cualquier cosa imaginable; el infinito sobre su cabeza. Sin embargo, sin que nos demos cuenta, es el propio Mago quien sostiene la mesa con su pierna en la pata que falta (…) Como principio mínimo de infinitas posibilidades es el dígito binario de [...]]]></description>
										<content:encoded><![CDATA[<p style="text-align: justify;"><span style="color: #4c4c4c;"><em>(…) el Mago arroja los 4 elementos; con los que puede hacer cualquier cosa imaginable; el infinito sobre su cabeza. Sin embargo, sin que nos demos cuenta, es el propio Mago quien sostiene la mesa con su pierna en la pata que falta (…)</em> </span></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Como principio mínimo de infinitas posibilidades es el dígito binario de la interacción, una ventana de posibilidades, un desencadenante, un activador; para nosotros, el comienzo.</span></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Video, captura de movimiento e interacción.</span></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Imaginemos que un fragmento de la imagen de vídeo fuese capaz de activar un proceso o interrumpirlo, en función de la luminosidad de los pixeles que albergase. Ese fragmento de la imagen, al que llamaremos el área de activación, se comportaría como un botón que podríamos pulsar interponiendo nuestro cuerpo entre el fondo del espacio grabado y la cámara, de forma que modifiquemos la luminosidad de los pixeles contenidos en dicha área.</span></p>
<p><a href="./../../../../wp-content/uploads/2015/01/trigger-area.png"><img decoding="async" class="alignnone wp-image-811 size-large" src="./../../../../wp-content/uploads/2015/01/trigger-area-1024x140.png" alt="trigger-area" width="1024" height="140" srcset="./../../../../wp-content/uploads/2015/01/trigger-area-1024x140.png 1024w, ./../../../../wp-content/uploads/2015/01/trigger-area-300x41.png 300w, ./../../../../wp-content/uploads/2015/01/trigger-area.png 1478w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p style="text-align: justify;"><span style="color: #4c4c4c;">Las áreas de activación son como los <i>buquets</i> de un sensor de una cámara digital, acumulan energía procedente de la luz, en este caso, almacenan la suma de los valores de luminosidad de los pixeles que albergan. Haciendo una media de todos los valores acumulados [ total / nº de pixeles ] podemos conocer la luminosidad media de la zona y establecer un umbral por encima del cual consideramos el área llena o por debajo del cual la consideramos vacía, asignando así un valor lógico [ boolean ] a la misma. El área se transforma, de este modo, en un botón que está encendido o apagado y que puede enviar datos cuando cambia de estado, si así lo decidimos, activándola o desactivándola.</span></p>
<p><a title="TriggerAreas - Github Alg-a" href="https://github.com/alg-a/herm3TICa/tree/master/exploracion%20pruebas%20y%20juegos/triggerAreas" target="_blank">https://github.com/alg-a/herm3TICa/tree/master/exploracion pruebas y juegos/triggerAreas</a></p>
]]></content:encoded>
					
					<wfw:commentRss>./../../../../el-mago-areas-de-activacion/feed/index.html</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Alfombra de Sierpinski</title>
		<link>./../../../../alfombra-de-sierpinski/index.html</link>
					<comments>./../../../../alfombra-de-sierpinski/index.html#respond</comments>
		
		<dc:creator><![CDATA[man2hauser]]></dc:creator>
		<pubDate>Sat, 22 Nov 2014 17:54:47 +0000</pubDate>
				<category><![CDATA[Alfombra de Sierpinski]]></category>
		<category><![CDATA[code]]></category>
		<category><![CDATA[interactivos]]></category>
		<category><![CDATA[Investigación]]></category>
		<category><![CDATA[Máquina Abstracta]]></category>
		<guid isPermaLink="false">./../../../../index.html?p=566</guid>

					<description><![CDATA[Comenzamos nuestro periodo de investigación y diseño de los dispositivos básicos que configurarán #herm3TICa como espacio interactivo de acción y movimiento. Uno de los retos principales es el de &#8220;mapear&#8221; de alguna manera un espacio tridimensional, como es la &#8220;sala de revelados&#8221; en la que intervendremos. Pero esta sala la tenemos que construir! Para ello [...]]]></description>
										<content:encoded><![CDATA[<p align="justify">Comenzamos nuestro periodo de investigación y diseño de los dispositivos básicos que configurarán #herm3TICa como espacio interactivo de acción y movimiento. Uno de los retos principales es el de &#8220;mapear&#8221; de alguna manera un espacio tridimensional, como es la &#8220;sala de revelados&#8221; en la que intervendremos. Pero esta sala la tenemos que construir! Para ello hemos encontrado en primer lugar una configuración para el suelo: una alfombra! Se trata de la llamada <a title="Alfombra de Sierpinski" href="http://es.wikipedia.org/wiki/Alfombra_de_Sierpinski">Alfombra de Sierpinski</a> la cual expresa en dos dimensiones el conjunto de Cantor. Es decir, es un conjunto compacto, no numerable y de medida nula. Además es <b>universal</b> para todo objeto compacto del plano. Así, cualquier curva dibujada en el plano con las autointersecciones que queramos, por complicada que sea, será homeomorfa a un subconjunto de la alfombra.</p>
<p align="justify"><a href="./../../../../wp-content/uploads/2014/11/IMG_20141122_204751.jpg"><img decoding="async" class="alignnone size-medium wp-image-572" src="./../../../../wp-content/uploads/2014/11/IMG_20141122_204751-300x225.jpg" alt="PageLines-IMG_20141122_204751.jpg" width="300" height="225" srcset="./../../../../wp-content/uploads/2014/11/IMG_20141122_204751-300x225.jpg 300w, ./../../../../wp-content/uploads/2014/11/IMG_20141122_204751-1024x768.jpg 1024w" sizes="(max-width: 300px) 100vw, 300px" /></a></p>
<p align="justify">A nosotr@s nos interesa como espacio en el que distribuir sensores y actuadores en el suelo, estableciendo así un plano básico de interacción y computación que nos da de una manera más o menos fácil las coordenadas de posición, en un principio, en el plano X-Y del suelo. Ahora bien, dadas las características de la alfombra, dicho plano, contiene cualquier curva posible que imaginemos, como un subconjunto de sí mismo, por lo que podría contener nuestro volumen, abatido, incluyendo el eje Z también, con lo que de alguna manera, podríamos hacer corresponder cualquier cambio de posición en el plano real 3D de la sala, con un desplazamiento de una curva, abatiendo la figura en la alfombra. Esto es lo que de alguna manera pasa en la &lt;a title=&#8221;máquina abstracta&#8221; href=&#8221;./../../../../maquina-abstracta/&/index.html#8221;&gt;&lt;strong&gt;carta número 1 del Mago&lt;/strong&gt;&lt;/a&gt;: el plano de la mesa contiene de alguna manera una dimensión exterior a sí misma, que es el propio Mago. Por eso soporta, sutilmente, la mesa con su pierna como 4º pie. Porque la realidad virtual la generamos nosotr@s mism@s con un pie, todavía, anclado al suelo. Ese es el punto que computamos físicamente en la alfombra; el resto es proyectado en los monitores que nos dan las cámaras en el espacio videovigilado.</p>
]]></content:encoded>
					
					<wfw:commentRss>./../../../../alfombra-de-sierpinski/feed/index.html</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
